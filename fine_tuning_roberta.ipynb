{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1A8MhXtJTGi"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gqZP7THdu4MS"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip show transformers\n",
        "!pip show accelerate\n",
        "!pip install transformers[torch] -U\n",
        "!pip install accelerate -U\n",
        "!pip install transformers\n",
        "!pip install pytorch-lightning\n",
        "!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERNlGyweKUhm"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfScIJapKW5X",
        "outputId": "ae26e73b-07d1-4146-fabb-79b24e7f589b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-12-efa41bed1490>:21: DtypeWarning: Columns (17,18,19,20,21,22,23,24,25,26,27,28,29,39,40,41,42,43,44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  toxicity_train_df = pd.read_csv('toxicity_train.csv', on_bad_lines='skip', quoting=csv.QUOTE_NONE)\n",
            "<ipython-input-12-efa41bed1490>:26: DtypeWarning: Columns (17,18,19,20,21,22,23,24,25,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  toxicity_test_df = pd.read_csv('toxicity_test.csv', on_bad_lines='skip', quoting=csv.QUOTE_NONE)\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "\n",
        "# 1. Prepare Dataset\n",
        "# 2. Load pretrained Tokenizer, call it with dataset -> encoding\n",
        "# 3. Build PyTorth Dataset with encodings\n",
        "# 4. Load pretrained Model\n",
        "# 5. Load HF Trainer and train it\n",
        "\n",
        "\n",
        "# Train Data - 52662 rows after pre-processing (done above)\n",
        "toxicity_train_df = pd.read_csv('toxicity_train.csv', on_bad_lines='skip', quoting=csv.QUOTE_NONE)\n",
        "toxicity_train_df = toxicity_train_df.dropna()\n",
        "\n",
        "\n",
        "# Test Data - 7287 rows after pre-processing\n",
        "toxicity_test_df = pd.read_csv('toxicity_test.csv', on_bad_lines='skip', quoting=csv.QUOTE_NONE)\n",
        "toxicity_test_df = toxicity_test_df.dropna()\n",
        "\n",
        "\n",
        "# Sampling for CPU use\n",
        "# fraction = 0.1\n",
        "\n",
        "# toxicity_train_df = toxicity_train_df.sample(frac=fraction, random_state=42)\n",
        "# toxicity_test_df = toxicity_test_df.sample(frac=fraction, random_state=42)\n",
        "\n",
        "# # Reset index for consistency\n",
        "# toxicity_train_df.reset_index(drop=True, inplace=True)\n",
        "# toxicity_test_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# List of categories to check\n",
        "categories_to_check = ['obscene', 'sexual_explicit', 'threat', 'insult', 'identity_attack']\n",
        "\n",
        "# Check if any category is above the 0.5 threshold\n",
        "toxicity_train_df[categories_to_check] = toxicity_train_df[categories_to_check].apply(pd.to_numeric, errors='coerce')\n",
        "toxicity_test_df[categories_to_check] = toxicity_test_df[categories_to_check].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Check if any category is above the 0.5 threshold\n",
        "toxicity_train_df['toxic'] = (toxicity_train_df[categories_to_check] >= 0.5).any(axis=1).astype(float)\n",
        "toxicity_test_df['toxic'] = (toxicity_test_df[categories_to_check] >= 0.5).any(axis=1).astype(float)\n",
        "\n",
        "# Convert boolean values to 1.0 for True and 0.0 for False\n",
        "toxicity_train_df['toxic'] = toxicity_train_df['toxic'].astype(float)\n",
        "toxicity_test_df['toxic'] = toxicity_test_df['toxic'].astype(float)\n",
        "\n",
        "toxicity_train_df = toxicity_train_df[['comment_text', 'toxic', 'obscene', 'sexual_explicit', 'threat', 'insult', 'identity_attack']]\n",
        "toxicity_test_df = toxicity_test_df[['comment_text', 'toxic', 'obscene', 'sexual_explicit', 'threat', 'insult', 'identity_attack']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckNEOfOt7JY0"
      },
      "source": [
        "Test Lengths of DFs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEr4-GKc7LG4",
        "outputId": "e9a4c2c7-8c60-4a78-95a4-05ecfdd33ba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17016\n",
            "7287\n"
          ]
        }
      ],
      "source": [
        "print(len(toxicity_train_df))\n",
        "print(len(toxicity_test_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCaSSAkv-L2D"
      },
      "source": [
        "# Visualization of toxicity in train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "Wh3Wr23h-Nwl",
        "outputId": "8f9f0b6d-95eb-4ebb-df6a-15ac6c4f4684"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Count toxic and non-toxic comments\n",
        "toxic_count = toxicity_train_df['toxic'].sum()\n",
        "non_toxic_count = len(toxicity_train_df) - toxic_count\n",
        "\n",
        "# Plot side-by-side bars for toxic and non-toxic comments\n",
        "labels = ['Toxic Comments', 'Non-Toxic Comments']\n",
        "counts = [toxic_count, non_toxic_count]\n",
        "\n",
        "plt.bar(labels, counts, color=['red', 'blue'])\n",
        "plt.ylabel('Comment Count')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQBDfIDTAVmi"
      },
      "source": [
        "# Visualization of toxicity in test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "vMgpw28TAYN6",
        "outputId": "e3e38baf-b476-44db-96bf-61f4f66e0993"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Count toxic and non-toxic comments\n",
        "toxic_count = toxicity_test_df['toxic'].sum()\n",
        "non_toxic_count = len(toxicity_test_df) - toxic_count\n",
        "\n",
        "# Plot side-by-side bars for toxic and non-toxic comments\n",
        "labels = ['Toxic Comments', 'Non-Toxic Comments']\n",
        "counts = [toxic_count, non_toxic_count]\n",
        "\n",
        "plt.bar(labels, counts, color=['red', 'blue'])\n",
        "plt.ylabel('Comment Count')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWP0mBB9ZFf4"
      },
      "source": [
        "# Splitting and Labelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LUVKLSjZKHn",
        "outputId": "b70662d5-5480-4e31-d4b9-69f6acef5a96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_texts:\n",
            "[' so sad they\\'re no longer doing it.\"', ' send them to TES in TN or PAWS in CA.\"', ' and that was because of people moving here because of that stupid show.\"', ' either in person or by proxy. That just doesn\\'t set right for me.\"', ' and their god supports them with the action they\\'ve taken.  Intelligent or intellectually limited all these militia\\'s attract a very dangerous group of people with crackpot ideas.  Please don\\'t feel sorry for them they have chosen the path they have taken that could limit your rights and mine.\"']\n",
            "train_labels:\n",
            "   toxic\n",
            "0    0.0\n",
            "1    0.0\n",
            "2    0.0\n",
            "3    0.0\n",
            "4    0.0\n",
            "test_texts\n",
            "['BS !', 'Hodad...does your user handle refer to your daughter??', \"Many of them were wearing red Na'i Aupuni shirts.  Does that not show support for federal recognition?\", '\"Methinks your comment is indicative of your need to understand the Christian faith which does not require the subservience of woman as much as care and love for them by the man - \"\"as Christ loved the church\"\".\"', \"And sometimes it's just salting the earth...\"]\n",
            "test_labels:\n",
            "   toxic\n",
            "0    0.0\n",
            "1    0.0\n",
            "2    0.0\n",
            "3    0.0\n",
            "4    0.0\n"
          ]
        }
      ],
      "source": [
        "model_name = \"roberta-base\"\n",
        "\n",
        "toxicity_train_df.reset_index(drop=True, inplace=True)\n",
        "toxicity_test_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "X_train = toxicity_train_df[['comment_text']].reset_index(drop=True)\n",
        "X_train = X_train.dropna()\n",
        "\n",
        "# y_train = toxicity_train_df[['obscene', 'identity_attack', 'insult', 'threat', 'sexual_explicit']]\n",
        "y_train = toxicity_train_df[['toxic']].reset_index(drop=True)\n",
        "y_train = y_train.dropna()\n",
        "# toxicity_train_df.info()\n",
        "\n",
        "\n",
        "# toxicity_test_df.info()\n",
        "X_test = toxicity_test_df[['comment_text']].reset_index(drop=True)\n",
        "X_test = X_test.dropna()\n",
        "# # y_test = toxicity_test_df[['obscene', 'identity_attack', 'insult', 'threat', 'sexual_explicit']]\n",
        "y_test = toxicity_test_df[['toxic']].reset_index(drop=True)\n",
        "y_test = y_test.dropna()\n",
        "\n",
        "\n",
        "train_texts = X_train['comment_text'].tolist()\n",
        "train_labels = y_train\n",
        "test_texts = X_test['comment_text'].tolist()\n",
        "test_labels = y_test\n",
        "\n",
        "# See examples of texts & labels\n",
        "print(\"train_texts:\")\n",
        "print(train_texts[:5])\n",
        "print(\"train_labels:\")\n",
        "print(train_labels[:5])\n",
        "print(\"test_texts\")\n",
        "print(test_texts[:5])\n",
        "print(\"test_labels:\")\n",
        "print(test_labels[:5])\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PaVNtTit2tc"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "m54fSxNKt4oC"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "\n",
        "\n",
        "class ToxicDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx]).float()\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n",
        "\n",
        "train_labels = train_labels['toxic'].reset_index(drop=True)\n",
        "val_labels = val_labels['toxic'].reset_index(drop=True)\n",
        "test_labels = test_labels['toxic'].reset_index(drop=True)\n",
        "\n",
        "# Convert Pandas Series to lists\n",
        "train_labels_list = train_labels.tolist()\n",
        "val_labels_list = val_labels.tolist()\n",
        "test_labels_list = test_labels.tolist()\n",
        "\n",
        "train_dataset = ToxicDataset(train_encodings, train_labels)\n",
        "val_dataset = ToxicDataset(val_encodings, val_labels)\n",
        "test_dataset = ToxicDataset(test_encodings, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4spOoBGGwLqb"
      },
      "source": [
        "# Tokenizer + Encodings + Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "65ed2aa7abc24f11b4ccb23c4fa16b74",
            "17ac9e3ef4b94b3597e2d5155b8558af",
            "9534b21d7ec447d0b4b9dce550bf7ae6",
            "a2f667ac3fc4445388c17624919ff3fe",
            "df4f37c867ba4cd0814e6dfb733dc4a3",
            "b33a964b153840ae85801297f99ba21c",
            "105fb1680e44477e9094194282e3c210",
            "476db3c57e364d8dafb37b08f8c7d669",
            "84359705ce84425aad6ad5b0b5fd174f",
            "a768f32218c4482ca161a023cdb1d1c5",
            "5c637eb4660e49f58135add9ba3f446d"
          ]
        },
        "id": "gLsm7774wWa5",
        "outputId": "34f591f8-4290-45ce-ac7b-94a193ae6a4f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65ed2aa7abc24f11b4ccb23c4fa16b74",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='510' max='1702' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 510/1702 32:33 < 1:16:23, 0.26 it/s, Epoch 0/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.307400</td>\n",
              "      <td>0.195142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.177800</td>\n",
              "      <td>0.151006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.131700</td>\n",
              "      <td>0.147791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.150600</td>\n",
              "      <td>0.163527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.115700</td>\n",
              "      <td>0.148615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.211000</td>\n",
              "      <td>0.146421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.162800</td>\n",
              "      <td>0.141251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.120600</td>\n",
              "      <td>0.143655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.185600</td>\n",
              "      <td>0.147561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.147000</td>\n",
              "      <td>0.142065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.141600</td>\n",
              "      <td>0.147825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.157400</td>\n",
              "      <td>0.176895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.186300</td>\n",
              "      <td>0.154717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.145500</td>\n",
              "      <td>0.147280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.147100</td>\n",
              "      <td>0.155740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.168000</td>\n",
              "      <td>0.148872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.191000</td>\n",
              "      <td>0.147039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.153100</td>\n",
              "      <td>0.148763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.159200</td>\n",
              "      <td>0.150814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.150600</td>\n",
              "      <td>0.147104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.159400</td>\n",
              "      <td>0.160015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.163700</td>\n",
              "      <td>0.153323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.170200</td>\n",
              "      <td>0.152097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.141800</td>\n",
              "      <td>0.182969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.174600</td>\n",
              "      <td>0.152779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.124500</td>\n",
              "      <td>0.148013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.192800</td>\n",
              "      <td>0.147948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.171600</td>\n",
              "      <td>0.147628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.181600</td>\n",
              "      <td>0.149942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.175300</td>\n",
              "      <td>0.147097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.116700</td>\n",
              "      <td>0.155542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.115800</td>\n",
              "      <td>0.147290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.178600</td>\n",
              "      <td>0.147666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.150300</td>\n",
              "      <td>0.157679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.141900</td>\n",
              "      <td>0.155167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.177700</td>\n",
              "      <td>0.150737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.158900</td>\n",
              "      <td>0.155853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.173500</td>\n",
              "      <td>0.156806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.174300</td>\n",
              "      <td>0.150697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.127700</td>\n",
              "      <td>0.147093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.195400</td>\n",
              "      <td>0.159225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.182600</td>\n",
              "      <td>0.170688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.168300</td>\n",
              "      <td>0.147260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.169000</td>\n",
              "      <td>0.154521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.173600</td>\n",
              "      <td>0.150264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.138600</td>\n",
              "      <td>0.154959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.156400</td>\n",
              "      <td>0.153188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.144500</td>\n",
              "      <td>0.147317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.185700</td>\n",
              "      <td>0.151234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.154100</td>\n",
              "      <td>0.147612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.165500</td>\n",
              "      <td>0.147110</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=200,\n",
        "    learning_rate=1e-4,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        ")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained('roberta-base', num_labels=1)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1, early_stopping_threshold=0.02)],\n",
        ")\n",
        "trainer.train()\n",
        "\n",
        "model.save_pretrained('/results/fine_tuned_roberta_model')\n",
        "\n",
        "# text = \"Replace me by any text you'd like.\"\n",
        "# encoded_input = tokenizer(text, return_tensors='pt')\n",
        "# output = model(**encoded_input)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcEulzfF5at2"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "yRuSNgIQ5fz1",
        "outputId": "587a6656-f08e-41b5-beee-4143f6046210"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.1476123332977295, 'eval_runtime': 31.9778, 'eval_samples_per_second': 106.449, 'eval_steps_per_second': 1.689, 'epoch': 0.6}\n",
            "Accuracy: 0.8207990599294948\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      1.00      0.90      2794\n",
            "         1.0       0.00      0.00      0.00       610\n",
            "\n",
            "    accuracy                           0.82      3404\n",
            "   macro avg       0.41      0.50      0.45      3404\n",
            "weighted avg       0.67      0.82      0.74      3404\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Use the trained model for evaluation\n",
        "eval_results = trainer.evaluate()\n",
        "\n",
        "# Print evaluation results\n",
        "print(eval_results)\n",
        "\n",
        "# Make predictions on the validation set\n",
        "predictions = trainer.predict(val_dataset)\n",
        "\n",
        "# Convert predictions to probabilities and get class labels\n",
        "predicted_probabilities = torch.nn.functional.softmax(torch.tensor(predictions.predictions), dim=1)\n",
        "predicted_labels = torch.argmax(predicted_probabilities, dim=1)\n",
        "\n",
        "# Flatten the true labels\n",
        "true_labels = val_labels.values.flatten()\n",
        "\n",
        "# Calculate accuracy and print classification report\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(classification_report(true_labels, predicted_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vB7-tPE46AzI"
      },
      "source": [
        "# Predictions on Twitch Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eA8lhxmU6C7T",
        "outputId": "5e20336e-8c23-4b9a-c275-faf98f3b5f4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           user                                       comment_text toxic\n",
            "0    firstdjinn  Confused why people are spamming things like J...    no\n",
            "1        zCrean       Nice thats my first time in Hasan Lifestream    no\n",
            "2     AfroTohru     THE ONE PIECE IS REAL LETSGO NEWS TODAY LETSGO    no\n",
            "3  Julian4Mayor  Dont forget to check ur cocks before stream st...    no\n",
            "4   RogueStereo  THE HASANABI IS REAL LETSGO THE HASANABI IS RE...    no\n",
            "5   eddyeduardo        hey guys I'm finally here early, I love you    no\n",
            "text_to_pred:\n",
            "Confused why people are spamming things like Jupijej or Jupijej ? You can't see the emotes! Download the Jupijej browser extension to improve your chat experience! Jupijej\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389971733093262}]\n",
            "text_to_pred:\n",
            "Nice thats my first time in Hasan Lifestream\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5390006303787231}]\n",
            "text_to_pred:\n",
            "THE ONE PIECE IS REAL LETSGO NEWS TODAY LETSGO\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.539000391960144}]\n",
            "text_to_pred:\n",
            "Dont forget to check ur cocks before stream starts\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389976501464844}]\n",
            "text_to_pred:\n",
            "THE HASANABI IS REAL LETSGO THE HASANABI IS REAL LETSGO\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5390011072158813}]\n",
            "text_to_pred:\n",
            "hey guys I'm finally here early, I love you\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389986038208008}]\n",
            "text_to_pred:\n",
            "that was crazy timing i ramdomly clicked on him\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5390000939369202}]\n",
            "text_to_pred:\n",
            "i just clicked without notification bois had a feeling\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389981865882874}]\n",
            "text_to_pred:\n",
            "HYPERPOGGER I was here on accident. Catching up on yesterday HYPERPOGGER\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5390005111694336}]\n",
            "text_to_pred:\n",
            "got here before the notif, yikes I have a problem\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389952063560486}]\n",
            "text_to_pred:\n",
            "nakedave587 subscribed with Prime. They've subscribed for 2 months! LFG\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389999151229858}]\n",
            "text_to_pred:\n",
            "nakedave587 just subbed using Prime for 2 months! bleedPurple https://twitch.amazon.com/tp\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389998555183411}]\n",
            "text_to_pred:\n",
            "@rythympnxa naber agam @HasanAbi izlemeye mi geldin sende KappaRoss\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.539000391960144}]\n",
            "text_to_pred:\n",
            "henlow everyone. hope yall are taking care of yourselves uwu\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389970541000366}]\n",
            "text_to_pred:\n",
            "!leftovers abyssabyss2445 Most every thursday he's live on youtube with H3H3\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389999747276306}]\n",
            "text_to_pred:\n",
            "Just got out the mental hospital missed this stream the most\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389968752861023}]\n",
            "text_to_pred:\n",
            "hasL hasL hasL hasL hasRaid hasRaid hasL hasL hasL hasL\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5390020608901978}]\n",
            "text_to_pred:\n",
            "@abyssabyss2445 LEFTOVERS PODCAST LATEST EPISODE: Donald Trump Announced He's Running For President!- Leftovers #32 - https://youtu.be/ZeUeDjX4fJk | Find past episodes on the YouTube playlist t.co/NFgZp6hhzM and other platforms pod.link/1186098620\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389970541000366}]\n",
            "text_to_pred:\n",
            "delmer9713 subscribed at Tier 1. They've subscribed for 26 months, currently on a 26 month streak! VIBE\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389984846115112}]\n",
            "text_to_pred:\n",
            "@abyssabyss2445, he's always an hour or so late on Thursdays. He does 'Leftovers' with Ethan first Okayge\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389995574951172}]\n",
            "text_to_pred:\n",
            "y'all think he'll talk about the ticketmaster disaster?\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389975905418396}]\n",
            "text_to_pred:\n",
            "I hope everyone is having a great day hasL\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389990210533142}]\n",
            "text_to_pred:\n",
            "NODDERS BLAMMO INTRO NODDERS BLAMMO INTRO NODDERS BLAMMO INTRO NODDERS BLAMMO INTRO NODDERS BLAMMO INTRO NODDERS BLAMMO INTRO NODDERS BLAMMO INTRO NODDERS BLAMMO INTRO NODDERS BLAMMO INTRO\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389934778213501}]\n",
            "text_to_pred:\n",
            "dro1d_tv subscribed with Prime. They've subscribed for 3 months, currently on a 3 month streak! gameing\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.538999080657959}]\n",
            "text_to_pred:\n",
            "dro1d_tv just subbed using Prime for 3 months! bleedPurple https://twitch.amazon.com/tp\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.539000391960144}]\n",
            "text_to_pred:\n",
            "ur looking good today chat YEP nice cock\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5390018820762634}]\n",
            "text_to_pred:\n",
            "LETS GOOO I JUST GOT HOME! PERFECT TIMING\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389988422393799}]\n",
            "text_to_pred:\n",
            "I was so close to scamming boomers, then you libs scammed me (REAL BTW)\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.538998007774353}]\n",
            "text_to_pred:\n",
            "Hi chat hi mods hasGachi keffalHyper hasGachi hope everyones had their weed had their meds and everyones staying hydrated keffalHyper keffalL keffalHyper keffalL keffalHyper I hope you can pet a friendly animal today\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389986038208008}]\n",
            "text_to_pred:\n",
            "@SpaceCadetGalletas, hasHug have a nice day too hasL\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389998555183411}]\n",
            "text_to_pred:\n",
            "He does leftovers and still comes in twitch. Top G\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.538998544216156}]\n",
            "text_to_pred:\n",
            "LETS FUCKING GOOO, I just HAPPENED TO CHECK IF YOU WERE LIVE WOOOO\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389981269836426}]\n",
            "text_to_pred:\n",
            "LIVE POGGERS LIVE POGGERS LIVE POGGERS LIVE POGGERS LIVE POGGERS LIVE POGGERS\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5390031933784485}]\n",
            "text_to_pred:\n",
            "LIVE POGGERS LIVE POGGERS LIVE POGGERS LIVE POGGERS LIVE POGGERS\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5390036702156067}]\n",
            "text_to_pred:\n",
            "day 4823 of no pussy. My body abosorbs all the nutrients in my food, I produce no waste\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.538996696472168}]\n",
            "text_to_pred:\n",
            "i'm running for VP 2024 with Trump, (REAL BTW)\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.538999617099762}]\n",
            "text_to_pred:\n",
            "maestro_panda subscribed at Tier 1. They've subscribed for 42 months! \n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389984846115112}]\n",
            "text_to_pred:\n",
            "rewatching that Katy Perry vid react from yesterday bc that shit goes so hard\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389981865882874}]\n",
            "text_to_pred:\n",
            "silent_noodle3 subscribed with Prime. They've subscribed for 22 months! Lov ya Hassy 22 months les goooooo\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5390010476112366}]\n",
            "text_to_pred:\n",
            "silent_noodle3 just subbed using Prime for 22 months! bleedPurple https://twitch.amazon.com/tp\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389997363090515}]\n",
            "text_to_pred:\n",
            "i just got gifted a yungfika sub what is UP yungfi6PeepoSwe\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389959216117859}]\n",
            "text_to_pred:\n",
            "Hello Chat hasL peepoHey goodness is that a new haircut? hasTasty\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.538999617099762}]\n",
            "text_to_pred:\n",
            "I'm  a noob here but watch him on The leftovers With H3's Ethan. <3 <3\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389986038208008}]\n",
            "text_to_pred:\n",
            "D/M/Y is the right date format Hasan is wrong about this\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389988422393799}]\n",
            "text_to_pred:\n",
            "I hope everyones feeling alright today hasL keffalHyper keffalL\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389991998672485}]\n",
            "text_to_pred:\n",
            "Operation Boost Trump Signal is a go. we cant let the elite rebloodlicans in the deep state suppress our voice of the voiceless: Donald J Trump. please do your part.\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389978289604187}]\n",
            "text_to_pred:\n",
            "Glockt0pus subscribed with Prime. They've subscribed for 25 months, currently on a 23 month streak! 23 months of leftest degeneracy LETSGO\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389993786811829}]\n",
            "text_to_pred:\n",
            "Glockt0pus just subbed using Prime for 25 months! bleedPurple https://twitch.amazon.com/tp\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389994382858276}]\n",
            "text_to_pred:\n",
            "i'm running for preisdent 2024 (BIG IF TRUE)\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5390003323554993}]\n",
            "text_to_pred:\n",
            "LosPeepos orela es tiempo a ver el turco\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389969944953918}]\n",
            "text_to_pred:\n",
            "SoullessViking1 subscribed with Prime. They've subscribed for 14 months! 14mo leggo\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5390001535415649}]\n",
            "text_to_pred:\n",
            "SoullessViking1 just subbed using Prime for 14 months! bleedPurple https://twitch.amazon.com/tp\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.538999617099762}]\n",
            "text_to_pred:\n",
            "yall think itll work if i shoot my shot this time\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389966368675232}]\n",
            "text_to_pred:\n",
            "CHAT CAN WE ASK HIM ABT A PUPPY UPDATE peepoShy HYPERS CHAT CAN WE ASK HIM ABT A PUPPY UPDATE peepoShy HYPERS CHAT CAN WE ASK HIM ABT A PUPPY UPDATE peepoShy HYPERS CHAT CAN WE ASK HIM ABT A PUPPY UPDATE peepoShy HYPERS\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389986038208008}]\n",
            "text_to_pred:\n",
            "chat why isnt it letting me skip this part\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.538999080657959}]\n",
            "text_to_pred:\n",
            "HeyGuys Hi chat HeyGuys Hi chat HeyGuys Hi chat HeyGuys Hi chat HeyGuys Hi chat HeyGuys Hi chat HeyGuys Hi chat HeyGuys Hi chat\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.538997232913971}]\n",
            "text_to_pred:\n",
            "cassandrue subscribed with Prime. They've subscribed for 15 months, currently on a 15 month streak! 15 months, LETSGO\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.538998007774353}]\n",
            "text_to_pred:\n",
            "cassandrue just subbed using Prime for 15 months! bleedPurple https://twitch.amazon.com/tp\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389988422393799}]\n",
            "text_to_pred:\n",
            "Please consider donating to support the BLM protests nationwide. https://fossa.bot/l/blm-support bleedPurple blmCheer\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389987826347351}]\n",
            "text_to_pred:\n",
            "MY BCHAT ppHop MY BCHAT ppHop MY BCHAT ppHop MY BCHAT ppHop\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.539002001285553}]\n",
            "text_to_pred:\n",
            "melaniejit subscribed with Prime. They've subscribed for 8 months! let's go\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389982461929321}]\n",
            "text_to_pred:\n",
            "melaniejit just subbed using Prime for 8 months! bleedPurple https://twitch.amazon.com/tp\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389992594718933}]\n",
            "text_to_pred:\n",
            "Hobergos subscribed with Prime. They've subscribed for 7 months, currently on a 7 month streak! hoberg1BroccJam hoberg1BroccJam hoberg1BroccJam\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389986038208008}]\n",
            "text_to_pred:\n",
            "Hobergos just subbed using Prime for 7 months! bleedPurple https://twitch.amazon.com/tp\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389998555183411}]\n",
            "text_to_pred:\n",
            "Pog just got done doing a picket for portlands VA nurses\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389987826347351}]\n",
            "text_to_pred:\n",
            "@Mijnboot, oh i knew some commands disable when it goes live but i didnt know which\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.53899747133255}]\n",
            "text_to_pred:\n",
            "Harmegedon subscribed at Tier 1. They've subscribed for 17 months, currently on a 16 month streak! heres to another month of holding on, btw some cute girl at my therapists office gave me a huge hug so now Im crushing PogChamp\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389968752861023}]\n",
            "text_to_pred:\n",
            "HIMBIES 1 hour 7 minutes until next ad break\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389983654022217}]\n",
            "text_to_pred:\n",
            "@errehpe, peepoPog wait are you actually LosPeepos ?\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389989018440247}]\n",
            "text_to_pred:\n",
            "SensualChocolate666 subscribed at Tier 1. They've subscribed for 32 months! Hi chat hasL hasHi\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5390001535415649}]\n",
            "text_to_pred:\n",
            "Inediblelime subscribed at Tier 1. They've subscribed for 12 months! \n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389981865882874}]\n",
            "text_to_pred:\n",
            "quarantinewolf subscribed at Tier 1. They've subscribed for 24 months, currently on a 24 month streak! TWO YEARS HELLO CHAT hasL\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389997363090515}]\n",
            "text_to_pred:\n",
            "Wow didnt think I get here before the stream\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389970541000366}]\n",
            "text_to_pred:\n",
            "Covid is at my work again please pray friends\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.538998007774353}]\n",
            "text_to_pred:\n",
            "ITS SNOWING IN COLORADO ppOverheat LETSGO ITS SNOWING IN COLORADO ppOverheat LETSGO ITS SNOWING IN COLORADO ppOverheat LETSGO ITS SNOWING IN COLORADO ppOverheat LETSGO\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389943718910217}]\n",
            "text_to_pred:\n",
            "hi chat lets have a good day today <3\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389994978904724}]\n",
            "text_to_pred:\n",
            "yungpaczki subscribed at Tier 1. They've subscribed for 3 months, currently on a 2 month streak! kinda nice to come here early and vibe to the lofi :)\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389958620071411}]\n",
            "text_to_pred:\n",
            "@HasanAbi debate me, i'm a real doctor (REAL BTW)\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5390000939369202}]\n",
            "text_to_pred:\n",
            "CLOSING IN ON A YEAR OF BRAINROT LETS GOOO\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5390005111694336}]\n",
            "text_to_pred:\n",
            "Anybody else not getting go live notos from twitch?\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389990210533142}]\n",
            "text_to_pred:\n",
            "emilyridesaskateboard subscribed at Tier 1. They've subscribed for 20 months! \n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389991998672485}]\n",
            "text_to_pred:\n",
            "justinthesnail subscribed at Tier 1. They've subscribed for 18 months, currently on a 13 month streak! OOOO x13\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389990210533142}]\n",
            "text_to_pred:\n",
            "ITS SNOWING IN COLORADO ppOverheat LETSGO ITS SNOWING IN COLORADO ppOverheat LETSGO ITS SNOWING IN COLORADO ppOverheat LETSGO ITS SNOWING IN COLORADO ppOverheat LETSGO\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389943718910217}]\n",
            "text_to_pred:\n",
            "Did you hear about the Italian chef who died? He pasta way. He just ran out of thyme. Here today, gone tomato. His wife is still upset, cheese still not over it. We never sausage a tragedy coming. Ashes to ashes, crust to crust. Theres just not mushroom for Italian chefs in todays world. Want to know what the rough parts of Italy are called? The spaghetto. Dont call yourself Italian if you werent baptized in marinara sauce.\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389899611473083}]\n",
            "text_to_pred:\n",
            "Hi chat, hope you are all doing well hasL hasL hasL\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389995574951172}]\n",
            "text_to_pred:\n",
            "@godsfavelesbian Hey! The last time he talked about it, he mentioned he does still want to adopt but he might be going to Japan with Ludwig sometime soon. Due to that, it'll push back his plans to get a new dog\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389947891235352}]\n",
            "text_to_pred:\n",
            "Did you hear about the Italian chef who died? He pasta way. He just ran out of thyme. Here today, gone tomato. His wife is still upset, cheese still not over it. We never sausage a tragedy coming. Ashes to ashes, crust to crust. Theres just not mushroom for Italian chefs in todays world. Want to know what the rough parts of Italy are called? The spaghetto. Dont call yourself Italian if you werent baptized in marinara sauce.\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389899611473083}]\n",
            "text_to_pred:\n",
            "mrpayback3328 subscribed with Prime. They've subscribed for 24 months! WTF How has it been 2 years\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389994382858276}]\n",
            "text_to_pred:\n",
            "mrpayback3328 just subbed using Prime for 24 months! bleedPurple https://twitch.amazon.com/tp\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5390000939369202}]\n",
            "text_to_pred:\n",
            "@godsfavelesbian omg thank you so much for letting me know i appreciate it hasL thank u thank u\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389992594718933}]\n",
            "text_to_pred:\n",
            "@niloyyyy made it to the stream in time FeelsOkayMan\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389975905418396}]\n",
            "text_to_pred:\n",
            "guys im doubletapping but the video isnt skipping forward? is my app broken i usually watch on YouTube\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389998555183411}]\n",
            "text_to_pred:\n",
            "lups_13 subscribed with Prime. They've subscribed for 2 months! happy to be here\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389990210533142}]\n",
            "text_to_pred:\n",
            "lups_13 just subbed using Prime for 2 months! bleedPurple https://twitch.amazon.com/tp\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389997363090515}]\n",
            "text_to_pred:\n",
            "pelosi and i running for 2024 (REAL BTW)\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389980673789978}]\n",
            "text_to_pred:\n",
            "ti_monke subscribed with Prime. They've subscribed for 6 months, currently on a 6 month streak! COGGERS\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.538998544216156}]\n",
            "text_to_pred:\n",
            "ti_monke just subbed using Prime for 6 months! bleedPurple https://twitch.amazon.com/tp\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.538999617099762}]\n",
            "text_to_pred:\n",
            "HIMBIES DAYCARE OPEN HIMBIES DAYCARE OPEN HIMBIES DAYCARE OPEN HIMBIES DAYCARE OPEN HIMBIES DAYCARE OPEN HIMBIES DAYCARE OPEN HIMBIES DAYCARE OPEN HIMBIES DAYCARE OPEN HIMBIES DAYCARE OPEN\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389967560768127}]\n",
            "text_to_pred:\n",
            "pelosi is gonna be my VP (REAL BTW)\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.538999080657959}]\n",
            "text_to_pred:\n",
            "chat, once again hasan's icon on the left bar is not sorted properly, is he shadowbanned or some bullshit?\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389984846115112}]\n",
            "text_to_pred:\n",
            "@arienotari i studied it, stats is mad fun\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389984846115112}]\n",
            "text_to_pred:\n",
            "camgomi subscribed at Tier 1. They've subscribed for 9 months, currently on a 7 month streak! \n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389987826347351}]\n",
            "text_to_pred:\n",
            "surplusvaluetheory subscribed at Tier 1. They've subscribed for 31 months! \n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389989614486694}]\n",
            "text_to_pred:\n",
            "@darkroadtoNOwhere, wait wtf this tournamet is literally being held 30 mins away from my house\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389981865882874}]\n",
            "text_to_pred:\n",
            "@SmGRubyyy SmGRubyyy has been following HasanAbi for 2 years, 8 days and 21 hours\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389984250068665}]\n",
            "text_to_pred:\n",
            "sandyovals subscribed with Prime. They've subscribed for 6 months, currently on a 4 month streak! 6 month sub anniversary! How exciting!\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389981269836426}]\n",
            "text_to_pred:\n",
            "sandyovals just subbed using Prime for 6 months! bleedPurple https://twitch.amazon.com/tp\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.538999617099762}]\n",
            "text_to_pred:\n",
            "Hope youre having a great day chat hasL\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5390008091926575}]\n",
            "text_to_pred:\n",
            "Chatting Let's talk about how another streamer banned me to let the mods know I'm a toxic chatter\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389977097511292}]\n",
            "text_to_pred:\n",
            "LJandSarahTay subscribed with Prime. They've subscribed for 17 months, currently on a 8 month streak! Seventeeeeeeeen months!\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389991998672485}]\n",
            "text_to_pred:\n",
            "LJandSarahTay just subbed using Prime for 17 months! bleedPurple https://twitch.amazon.com/tp\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389997363090515}]\n",
            "text_to_pred:\n",
            "This is my favourite part of the stream\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389973521232605}]\n",
            "text_to_pred:\n",
            "@sussy_joao_do_brasil check your sort settings, should be high to low and also he just started\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389991998672485}]\n",
            "text_to_pred:\n",
            "@darkroadtoNOwhere, I think you need a ticket pepegeHmm\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389983654022217}]\n",
            "text_to_pred:\n",
            "@rights_gone_sadge LEFTOVERS PODCAST LATEST EPISODE: Donald Trump Announced He's Running For President!- Leftovers #32 - https://youtu.be/ZeUeDjX4fJk | Find past episodes on the YouTube playlist t.co/NFgZp6hhzM and other platforms pod.link/1186098620\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389970541000366}]\n",
            "text_to_pred:\n",
            "Hi everybody!! qtcJammies qtcJammies qtcJammies qtcJammies qtcJammies qtcJammies\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389977097511292}]\n",
            "text_to_pred:\n",
            "take a minute for the slow chat while it lasts :,)\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389982461929321}]\n",
            "text_to_pred:\n",
            "HOGGERS WARZONE 2.0 when is it time to HOG OUT during gamin brother?\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389994978904724}]\n",
            "text_to_pred:\n",
            "ayo chat, vote for me 2024 (REAL BTW)\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389996767044067}]\n",
            "text_to_pred:\n",
            "Hey chat peepoHey peepoHey peepoHey !!!!!! I wanted to stop in and tell you how much i love you and how I missed you since yesterday. I cannot WAIT to spend another fun filled day with all of you and papa Azan! Thank you to each and every one of you for making me laugh so hard my sides blast off into orbit on a daily basis. Peace and love to each one of you bois, girls, and NBs hasL hasL hasL\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389924645423889}]\n",
            "text_to_pred:\n",
            "LEFTOVERS PODCAST LATEST EPISODE: Donald Trump Announced He's Running For President!- Leftovers #32 - https://youtu.be/ZeUeDjX4fJk | Find past episodes on the YouTube playlist t.co/NFgZp6hhzM and other platforms pod.link/1186098620\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389963388442993}]\n",
            "text_to_pred:\n",
            "cum LETSGO cum LETSGO cum LETSGO cum LETSGO cum LETSGO cum LETSGO\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5390011668205261}]\n",
            "text_to_pred:\n",
            "Jupijej never Jupijej let Jupijej them Jupijej stop Jupijej you Jupijej from Jupijej jupiing Jupijej\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389941930770874}]\n",
            "text_to_pred:\n",
            "Jupijej BLAMO Jupijej BLAMO Jupijej BLAMO Jupijej BLAMO Jupijej BLAMO Jupijej\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389971137046814}]\n",
            "text_to_pred:\n",
            "Confused why people are spamming things like Jupijej or Jupijej ? You can't see the emotes! Download the Jupijej browser extension to improve your chat experience! Jupijej\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389971733093262}]\n",
            "text_to_pred:\n",
            "WHAAAT me when Gearbox bought Risk of Rain WHAAAT me when peezy approved of this transaction\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389983057975769}]\n",
            "text_to_pred:\n",
            "hi chat hope yall are having a good day <3\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389990210533142}]\n",
            "text_to_pred:\n",
            "hasChair hasChair hasChair hasChair  based af say more\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5390009880065918}]\n",
            "text_to_pred:\n",
            "Jupijej CUM Jupijej CUM Jupijej CUM Jupijej CUM Jupijej CUM Jupijej CUM Jupijej CUM\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389962196350098}]\n",
            "text_to_pred:\n",
            "peepoHey Hi chat! peepoHey Hope you're having a good day! peepoHey\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389970541000366}]\n",
            "text_to_pred:\n",
            "hey chat. look at me, i'm whiby \n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389989614486694}]\n",
            "text_to_pred:\n",
            "@PyroTFT but even if he has more viewers that some of my favorites already, he is not being brought up which affects visibility, dont remember changing anything but will check, thanks\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389954447746277}]\n",
            "text_to_pred:\n",
            "waiting for hasan groovy remix Prayge waiting for hasan groovy remix Prayge waiting for hasan groovy remix Prayge waiting for hasan groovy remix Prayge\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389986634254456}]\n",
            "text_to_pred:\n",
            "Hi Hasan, hi chat! hasHi dsaL dsaRose dsaTR\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5390008091926575}]\n",
            "text_to_pred:\n",
            "justKenneth subscribed with Prime. They've subscribed for 27 months! Got an ad  Madge  Twitch really dont let even a second pass with da prime before they serving the top of the hour\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389976501464844}]\n",
            "text_to_pred:\n",
            "justKenneth just subbed using Prime for 27 months! bleedPurple https://twitch.amazon.com/tp\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389994382858276}]\n",
            "text_to_pred:\n",
            "Im rolling a joint right now hasGachi keffalHyper hasGachi hope everyone can stay stoned today hasL keffalL\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389994382858276}]\n",
            "text_to_pred:\n",
            "Howdy chat! Hope everyone is healthy and happy today, stay strong comrades hasRaid\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389987826347351}]\n",
            "text_to_pred:\n",
            "waiting for hasan groovy remix Prayge waiting for hasan groovy remix Prayge\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389998555183411}]\n",
            "text_to_pred:\n",
            "Prayge cumzone Prayge cumzone Prayge cumzone Prayge cumzone Prayge cumzone\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.539000391960144}]\n",
            "text_to_pred:\n",
            "Hasan's reaction when he gets banned for saying R)  : WHAAAT\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389986634254456}]\n",
            "text_to_pred:\n",
            "Fear& PODCAST WITH WILL NEFF IS BACK!!! NEWEST EPISODE: HASAN PIKER JOINS 100 THIEVES | Fear&CouRageJD - https://youtu.be/vtJdlTj4wSM | POD LINKS: twitter.com/FearAndPod linktr.ee/fearand\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389960408210754}]\n",
            "text_to_pred:\n",
            "Jupijej if trump hits the jupijej he wins every state in 2024\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389981865882874}]\n",
            "text_to_pred:\n",
            "@grawvyrobber Thank you! That was awesome hasL Hope youre having a great day too! And cant wait to spend the day with yall too!\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389977693557739}]\n",
            "text_to_pred:\n",
            "sleephelp subscribed at Tier 1. They've subscribed for 12 months! hasKkona\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389996767044067}]\n",
            "text_to_pred:\n",
            "TheEliRiots subscribed at Tier 1. They've subscribed for 4 months! \n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389980673789978}]\n",
            "text_to_pred:\n",
            "I LOVE TO EAT ASS LETSGO I LOVE TO EAT ASS LETSGO I LOVE TO EAT ASS LETSGO I LOVE TO EAT ASS LETSGO\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389996767044067}]\n",
            "text_to_pred:\n",
            "BibleThump PMSTwin ShazBotstix BibleThump AsianGlow PMSTwin OneHand DAESuppy BibleThump PunchTrees DBstyle BibleThump SMOrc ShazBotstix FailFish SMOrc SMOrc SMOrc\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389982461929321}]\n",
            "text_to_pred:\n",
            "WHAAAT mfw hasan does the CLASSIC cussy explanation bit\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389994382858276}]\n",
            "text_to_pred:\n",
            "I love how the intro is chill but the stream is never chill KEKW\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389988422393799}]\n",
            "text_to_pred:\n",
            "gizmomacks gifted a Tier 1 sub to JuuzoFNGG! They have given 80 Gift Subs in the channel! \n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389965176582336}]\n",
            "text_to_pred:\n",
            "peepoHas Thank you gizmomacks for gifting JuuzoFNGG a Tier 1 sub!\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389986038208008}]\n",
            "text_to_pred:\n",
            "Frigeo subscribed at Tier 1. They've subscribed for 12 months! Jupijej I killed a medic in gaza\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.538998007774353}]\n",
            "text_to_pred:\n",
            "geesemanx subscribed with Prime. They've subscribed for 8 months! POG POG POG\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5390015244483948}]\n",
            "text_to_pred:\n",
            "geesemanx just subbed using Prime for 8 months! bleedPurple https://twitch.amazon.com/tp\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389996767044067}]\n",
            "text_to_pred:\n",
            "EnnLaRouche subscribed with Prime. They've subscribed for 5 months! \n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389994978904724}]\n",
            "text_to_pred:\n",
            "EnnLaRouche just subbed using Prime for 5 months! bleedPurple https://twitch.amazon.com/tp\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389997363090515}]\n",
            "text_to_pred:\n",
            "Republicans want to distance themselves from trump but the house is pushing for same petty grievances that nobody cared about,Thoughts?@Hasanabi\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389954447746277}]\n",
            "text_to_pred:\n",
            "WHAAAT the republican party is full of racists??\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389989018440247}]\n",
            "text_to_pred:\n",
            "xp9011 subscribed with Prime. They've subscribed for 16 months! \n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389993786811829}]\n",
            "text_to_pred:\n",
            "xp9011 just subbed using Prime for 16 months! bleedPurple https://twitch.amazon.com/tp\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389999747276306}]\n",
            "text_to_pred:\n",
            "Is chat ok today whats going on lol\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389989614486694}]\n",
            "text_to_pred:\n",
            "LEFTOVERS PODCAST LATEST EPISODE: Donald Trump Announced He's Running For President!- Leftovers #32 - https://youtu.be/ZeUeDjX4fJk | Find past episodes on the YouTube playlist t.co/NFgZp6hhzM and other platforms pod.link/1186098620\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389963388442993}]\n",
            "text_to_pred:\n",
            "WHAAAT no new ben shapiro flexing videos in 3 weeks\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389991402626038}]\n",
            "text_to_pred:\n",
            "Hi chat dnmL dnmL dnmL jmaria2L jmaria2L jmaria2L\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389991998672485}]\n",
            "text_to_pred:\n",
            "LosPeepos GuitarTime ESPERANDO A HASAN LosPeepos GuitarTime ESPERANDO A HASAN LosPeepos GuitarTime ESPERANDO A HASAN LosPeepos GuitarTime ESPERANDO A HASAN LosPeepos GuitarTime ESPERANDO A HASAN\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389947295188904}]\n",
            "text_to_pred:\n",
            "WHAAAT mfw gizmomacks' name is actually gizm o'macks\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389997959136963}]\n",
            "text_to_pred:\n",
            "Im faded AND a hoe hasGachi keffalHyper hasGachi\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5390008091926575}]\n",
            "text_to_pred:\n",
            "Just got done teaching high school chat I hope none of you were dicks to your (based leftist) teachers today\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389978885650635}]\n",
            "text_to_pred:\n",
            "@MisterNosaj LEFTOVERS PODCAST LATEST EPISODE: Donald Trump Announced He's Running For President!- Leftovers #32 - https://youtu.be/ZeUeDjX4fJk | Find past episodes on the YouTube playlist t.co/NFgZp6hhzM and other platforms pod.link/1186098620\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389968156814575}]\n",
            "text_to_pred:\n",
            "ppHop LETSGO ppHop LETSGO ppHop LETSGO ppHop LETSGO ppHop LETSGO ppHop LETSGO ppHop LETSGO\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389994382858276}]\n",
            "text_to_pred:\n",
            "hasL hasL hasL hasL hasL hasL hasL hasChair\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5390025973320007}]\n",
            "text_to_pred:\n",
            "hasSlam hasSlam hasSlam hasSlam hasSlam hasSlam hasSlam hasSlam\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5390023589134216}]\n",
            "text_to_pred:\n",
            "waddup chat  hasL hasL hasL hasL hasL\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5390005111694336}]\n",
            "text_to_pred:\n",
            "i took the weasly little liar to poland\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389996767044067}]\n",
            "text_to_pred:\n",
            "dmv_luke subscribed with Prime. They've subscribed for 7 months! \n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389992594718933}]\n",
            "text_to_pred:\n",
            "dmv_luke just subbed using Prime for 7 months! bleedPurple https://twitch.amazon.com/tp\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389997959136963}]\n",
            "text_to_pred:\n",
            "@snoops_kush No I think they want open borders\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389978289604187}]\n",
            "text_to_pred:\n",
            "HYPERNODDERS NODDERS HYPERNODDERS NODDERS HYPERNODDERS NODDERS HYPERNODDERS NODDERS HYPERNODDERS NODDERS HYPERNODDERS NODDERS HYPERNODDERS\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.538994312286377}]\n",
            "text_to_pred:\n",
            "HYPERNODDERS PHONK INTRO HYPERNODDERS PHONK INTRO HYPERNODDERS PHONK INTRO HYPERNODDERS PHONK INTRO HYPERNODDERS PHONK INTRO HYPERNODDERS PHONK INTRO HYPERNODDERS PHONK INTRO\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.538995623588562}]\n",
            "text_to_pred:\n",
            "LETSGO HYPERNODDERS LETSGO HYPERNODDERS LETSGO HYPERNODDERS LETSGO HYPERNODDERS LETSGO HYPERNODDERS\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389970541000366}]\n",
            "text_to_pred:\n",
            "hasSlam HYPERNODDERS hasSlam HYPERNODDERS hasSlam HYPERNODDERS hasSlam HYPERNODDERS\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389990210533142}]\n",
            "text_to_pred:\n",
            "HYPERNODDERS SmokeTime HYPERNODDERS SmokeTime HYPERNODDERS SmokeTime HYPERNODDERS SmokeTime HYPERNODDERS SmokeTime\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389990210533142}]\n",
            "text_to_pred:\n",
            "HYPERNODDERS hasanSmash HYPERNODDERS hasanSmash HYPERNODDERS hasanSmash HYPERNODDERS hasanSmash HYPERNODDERS hasanSmash HYPERNODDERS hasanSmash HYPERNODDERS hasanSmash\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389969348907471}]\n",
            "text_to_pred:\n",
            "hasPOGGIES hasWicked hasPOGGIES hasWicked hasPOGGIES hasWicked hasPOGGIES hasWicked hasPOGGIES\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389973521232605}]\n",
            "text_to_pred:\n",
            "HYPERNODDERS PHONK INTRO HYPERNODDERS PHONK INTRO HYPERNODDERS PHONK INTRO HYPERNODDERS PHONK INTRO HYPERNODDERS PHONK INTRO HYPERNODDERS PHONK INTRO HYPERNODDERS PHONK INTRO\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.538995623588562}]\n",
            "text_to_pred:\n",
            "love the qt merch man im sad i missed that drop @HasanAbi\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5390007495880127}]\n",
            "text_to_pred:\n",
            "NODDERS RapThis NODDERS RapThis NODDERS RapThis NODDERS RapThis NODDERS RapThis\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389994382858276}]\n",
            "text_to_pred:\n",
            "hasSlam AienPls hasSlam AienPls hasSlam AienPls hasSlam AienPls hasSlam AienPls hasSlam AienPls\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389997959136963}]\n",
            "text_to_pred:\n",
            "god this intro goes so fucking HARD HYPERNODDERS\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389994978904724}]\n",
            "text_to_pred:\n",
            "HYPERNODDERS SmokeTime HYPERNODDERS SmokeTime HYPERNODDERS SmokeTime HYPERNODDERS SmokeTime\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389994382858276}]\n",
            "text_to_pred:\n",
            "HYPERNODDERS hasSlam HYPERNODDERS hasSlam HYPERNODDERS hasSlam HYPERNODDERS hasSlam\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389990210533142}]\n",
            "text_to_pred:\n",
            "HYPERNODDERS  AlienPls HYPERNODDERS AlienPls HYPERNODDERS AlienPls HYPERNODDERS AlienPls\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389989018440247}]\n",
            "text_to_pred:\n",
            "hasSlam hasSlam hasSlam hasSlam hasSlam hasSlam hasSlam hasSlam hasSlam hasSlam\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5390016436576843}]\n",
            "text_to_pred:\n",
            "HYPERNODDERS  hasanSmash  HYPERNODDERS  hasanSmash  HYPERNODDERS  hasanSmash  HYPERNODDERS  hasanSmash  HYPERNODDERS  hasanSmash  HYPERNODDERS  hasanSmash  HYPERNODDERS  hasanSmash\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389991998672485}]\n",
            "text_to_pred:\n",
            "HYPERNODDERS SmokeTime HYPERNODDERS SmokeTime HYPERNODDERS SmokeTime HYPERNODDERS SmokeTime HYPERNODDERS SmokeTime\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389990210533142}]\n",
            "text_to_pred:\n",
            "HYPERNODDERS FUCK IT HYPERNODDERS FUCK IT HYPERNODDERS FUCK IT HYPERNODDERS FUCK IT HYPERNODDERS FUCK IT\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389990210533142}]\n",
            "text_to_pred:\n",
            "ApeDarwin subscribed at Tier 1. They've subscribed for 18 months, currently on a 18 month streak! Miz went to MuscleGirl first https://www.youtube.com/watch?v=aZ0SsqlVSTs&ab_channel=JustWatchingStreams\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389969944953918}]\n",
            "text_to_pred:\n",
            "An anonymous user is gifting 1 Tier 1 Subs to HasanAbi's community! \n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389973521232605}]\n",
            "text_to_pred:\n",
            "An anonymous user gifted a Tier 1 sub to garlicbreadwithsalad!  \n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.538998544216156}]\n",
            "text_to_pred:\n",
            "peepoHas Thank you AnAnonymousGifter for gifting garlicbreadwithsalad a Tier 1 sub!\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389994382858276}]\n",
            "text_to_pred:\n",
            "Fear& PODCAST WITH WILL NEFF IS BACK!!! NEWEST EPISODE: HASAN PIKER JOINS 100 THIEVES | Fear&CouRageJD - https://youtu.be/vtJdlTj4wSM | POD LINKS: twitter.com/FearAndPod linktr.ee/fearand\n",
            "prediction: [{'label': 'LABEL_0', 'score': 0.5389960408210754}]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-96f38833333f>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Apply the prediction function to each row in the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtwitch_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'roberta_prediction'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwitch_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Display the DataFrame with predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9566\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9567\u001b[0m         )\n\u001b[0;32m-> 9568\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9570\u001b[0m     def applymap(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-96f38833333f>\u001b[0m in \u001b[0;36mpredict_label\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtext_to_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comment_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_to_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text_to_pred:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_to_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_classification.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone\u001b[0m \u001b[0msuch\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m \u001b[0mper\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;31m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0m_legacy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"top_k\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1160\u001b[0m             )\n\u001b[1;32m   1161\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1162\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1066\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_classification.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"use_cache\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"use_cache\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_to_apply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_legacy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m         outputs = self.roberta(\n\u001b[0m\u001b[1;32m   1199\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         )\n\u001b[0;32m--> 835\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    836\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    522\u001b[0m                 )\n\u001b[1;32m    523\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    525\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    456\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from transformers import RobertaTokenizer\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load the fine-tuned model for inference\n",
        "tokenizer = RobertaTokenizer.from_pretrained('/content/results/checkpoint-500/')\n",
        "\n",
        "twitch_df = pd.read_csv('twitch_toxicity.csv')\n",
        "print(twitch_df.head(6))\n",
        "\n",
        "# Create a text classification pipeline\n",
        "classifier = pipeline('text-classification', model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Example function to apply the classifier to each row in the DataFrame\n",
        "def predict_label(row):\n",
        "    text_to_predict = row['comment_text']\n",
        "    prediction = classifier(text_to_predict)\n",
        "    print(\"text_to_pred:\")\n",
        "    print(text_to_predict)\n",
        "    print(f\"prediction: {prediction}\")\n",
        "    return prediction\n",
        "\n",
        "# Apply the prediction function to each row in the DataFrame\n",
        "twitch_df['roberta_prediction'] = twitch_df.apply(predict_label, axis=1)\n",
        "\n",
        "# Display the DataFrame with predictions\n",
        "print(twitch_df[['comment_text', 'roberta_prediction']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yqw8qYpfmtl_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "105fb1680e44477e9094194282e3c210": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17ac9e3ef4b94b3597e2d5155b8558af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b33a964b153840ae85801297f99ba21c",
            "placeholder": "",
            "style": "IPY_MODEL_105fb1680e44477e9094194282e3c210",
            "value": "model.safetensors: 100%"
          }
        },
        "476db3c57e364d8dafb37b08f8c7d669": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c637eb4660e49f58135add9ba3f446d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65ed2aa7abc24f11b4ccb23c4fa16b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17ac9e3ef4b94b3597e2d5155b8558af",
              "IPY_MODEL_9534b21d7ec447d0b4b9dce550bf7ae6",
              "IPY_MODEL_a2f667ac3fc4445388c17624919ff3fe"
            ],
            "layout": "IPY_MODEL_df4f37c867ba4cd0814e6dfb733dc4a3"
          }
        },
        "84359705ce84425aad6ad5b0b5fd174f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9534b21d7ec447d0b4b9dce550bf7ae6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_476db3c57e364d8dafb37b08f8c7d669",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_84359705ce84425aad6ad5b0b5fd174f",
            "value": 498818054
          }
        },
        "a2f667ac3fc4445388c17624919ff3fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a768f32218c4482ca161a023cdb1d1c5",
            "placeholder": "",
            "style": "IPY_MODEL_5c637eb4660e49f58135add9ba3f446d",
            "value": " 499M/499M [00:03&lt;00:00, 135MB/s]"
          }
        },
        "a768f32218c4482ca161a023cdb1d1c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b33a964b153840ae85801297f99ba21c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df4f37c867ba4cd0814e6dfb733dc4a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
