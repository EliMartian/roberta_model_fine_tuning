# -*- coding: utf-8 -*-
"""Fine-Tuning RoBERTa.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XqGKKEsIt1h3uKABPoHVDIbcsl0KTI9R

# Setup
"""

!pip show transformers
!pip show accelerate

!pip install transformers[torch] -U
!pip install accelerate -U

!pip install transformers
!pip install pytorch-lightning

"""# Imports and Visualize Data"""

# Imports
import csv
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Read CSV
toxicity_train_df = pd.read_csv('toxicity_train.csv', on_bad_lines='skip', quoting=csv.QUOTE_NONE)
toxicity_train_df = toxicity_train_df.dropna()

# List of categories to check
categories_to_check = ['obscene', 'sexual_explicit', 'threat', 'insult', 'identity_attack']

# Check if any category is above the 0.5 threshold
toxicity_train_df[categories_to_check] = toxicity_train_df[categories_to_check].apply(pd.to_numeric, errors='coerce')

# Check if any category is above the 0.5 threshold
toxicity_train_df['toxic'] = (toxicity_train_df[categories_to_check] >= 0.5).any(axis=1).astype(float)

# Convert boolean values to 1.0 for True and 0.0 for False
toxicity_train_df['toxic'] = toxicity_train_df['toxic'].astype(float)
toxicity_train_df = toxicity_train_df[['comment_text', 'toxic', 'obscene', 'sexual_explicit', 'threat', 'insult', 'identity_attack']]
print(toxicity_train_df.head(20))

# toxicity_train_df['id'] = range(len(toxicity_df))

# Count toxic and non-toxic comments
toxic_count = toxicity_train_df['toxic'].sum()
non_toxic_count = len(toxicity_train_df) - toxic_count

# Plot side-by-side bars for toxic and non-toxic comments
labels = ['Toxic Comments', 'Non-Toxic Comments']
counts = [toxic_count, non_toxic_count]

plt.bar(labels, counts, color=['red', 'blue'])
plt.ylabel('Comment Count')

plt.show()

"""# Pre-Processing"""

import torch
import torch.nn.functional as F
from torch.utils.data import Dataset
from transformers import Trainer, TrainingArguments
from sklearn.model_selection import train_test_split
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# 1. Prepare Dataset
# 2. Load pretrained Tokenizer, call it with dataset -> encoding
# 3. Build PyTorth Dataset with encodings
# 4. Load pretrained Model
# 5. Load HF Trainer and train it

model_name = "roberta-base"

# Train Data - 52662 rows after pre-processing (done above)
X_train = toxicity_train_df[['comment_text']]
y_train = toxicity_train_df[['obscene', 'identity_attack', 'insult', 'threat', 'sexual_explicit']]
# toxicity_train_df.info()

# Test Data - 7287 rows after pre-processing
toxicity_test_df = pd.read_csv('toxicity_test.csv', on_bad_lines='skip', quoting=csv.QUOTE_NONE)
toxicity_test_df = toxicity_test_df.dropna()
X_test = toxicity_test_df[['comment_text']]
y_test = toxicity_test_df[['obscene', 'identity_attack', 'insult', 'threat', 'sexual_explicit']]
# toxicity_test_df.info()

train_texts = X_train['comment_text'].tolist()
train_labels = y_train
test_texts = X_test['comment_text'].tolist()
test_labels = y_test

print("train_texts:")
print(train_texts)
print("train_labels:")
print(train_labels)
print("test_texts")
print(test_texts)
print("test_labels:")
print(test_labels)

train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.2)

"""# Dataset"""

# class toxicDataset(Dataset):
#     def __init__(self, encodings, labels):
#       self.encodings = encodings
#       self.labels = labels

#     def __getitem__(self, idx):
#       # return item
#       item = {key: torch.tensor([val[idx] for val in self.encodings.values()]) for key in self.encodings.keys()}
#       item['labels'] = torch.tensor(self.labels[idx])
#       return item

#     def __len__(self):
#       return len(self.labels)

class toxicDataset(Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        try:
            print("Encodings at index", idx, ":", self.encodings)
            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
            item['labels'] = torch.tensor(self.labels[idx])
            return item
        except Exception as e:
            print(f"Error at index {idx}: {e}")
            raise

    def __len__(self):
        return len(self.labels)


from transformers import RobertaTokenizer, RobertaModel
# Unfortunately no such thing exists :(
# from transformers import RobertaModelForSequenceClassification

tokenizer = RobertaTokenizer.from_pretrained('roberta-base')
train_encodings = tokenizer(train_texts, truncation=True, padding=True)
val_encodings = tokenizer(val_texts, truncation=True, padding=True)
test_encodings = tokenizer(test_texts, truncation=True, padding=True)

train_dataset = toxicDataset(train_encodings, train_labels)
val_dataset = toxicDataset(val_encodings, val_labels)
test_dataset = toxicDataset(test_encodings, test_labels)

"""# Tokenizer + Encodings + Training"""

from transformers import RobertaTokenizer, RobertaModel

# Unfortunately no such thing exists :(
# from transformers import RobertaModelForSequenceClassification

tokenizer = RobertaTokenizer.from_pretrained('roberta-base')
train_encodings = tokenizer(train_texts, truncation=True, padding=True)
val_encodings = tokenizer(val_texts, truncation=True, padding=True)
test_encodings = tokenizer(test_texts, truncation=True, padding=True)

train_dataset = toxicDataset(train_encodings, train_labels)
val_dataset = toxicDataset(val_encodings, val_labels)
test_dataset = toxicDataset(test_encodings, test_labels)

training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=2,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=64,
    warmup_steps=500,
    learning_rate=5e-5,
    weight_decay=0.01,
    logging_dir='./logs',
    logging_steps=10,
)

model = AutoModelForSequenceClassification.from_pretrained('roberta-base')

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset
)

trainer.train()

# text = "Replace me by any text you'd like."
# encoded_input = tokenizer(text, return_tensors='pt')
# output = model(**encoded_input)

"""# Try Native PyTorch Training Loop instead of Hugging Face Trainer"""

from torch.utils.data import DataLoader
from transformers import AdamW

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')

model = AutoModelForSequenceClassification.from_pretrained('roberta-base')
model.to(device)
model.train()

train_loader = DataLoader(train_dataset, batch_size=16)
optim = AdamW(model.parameters(), lr=5e-5)

print("Dataset length:", len(train_loader.dataset))
print(train_loader.dataset.encodings.keys())
# Errors on the line below
print("Keys of the first item:", list(train_loader.dataset[0].keys()))


num_train_epochs = 2
for epoch in range(num_train_epochs):
  for batch in train_loader:
    optim.zero_grad()
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    labels = batch['labels'].to(device)

    outputs = model(input_ids, attention_mask=attention_mask, labels=labels)

    loss = outputs[0]
    loss.backward()
    optim.step()

model.eval()